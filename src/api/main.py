# ============================================================================
# DATA ENGINE RECOMMENDATION API
# ============================================================================
# This module provides a FastAPI-based recommendation service that generates
# personalized project recommendations using machine learning algorithms.
# ============================================================================

from typing import Any
from uuid import UUID

from fastapi import Depends, FastAPI, HTTPException, Path, Query
from pydantic import BaseModel, Field
from sqlalchemy.orm import Session

from src.application.services.recommendation import RecommendationService
from src.application.services.user_interest_profile import UserInterestProfileService
from src.domain.models.schema import Project
from src.infrastructure.logger import log
from src.infrastructure.postgres.database import SessionLocal

# ============================================================================
# LOGGING CONFIGURATION
# ============================================================================

# Using the default logger instance from the logger module

# ============================================================================
# PYDANTIC MODELS - API RESPONSE SCHEMAS
# ============================================================================




class RecommendationResponse(BaseModel):
    """
    Response model for project recommendations.

    Contains the user ID, list of recommended project UUIDs, and total count.
    The recommendations are ordered by relevance (most similar projects first).
    """

    user_id: UUID = Field(
        ...,
        description="The UUID of the user for whom recommendations were generated",
        example="a75337f8-f424-4f0c-90c2-2d7026b5bce8",
    )
    recommended_projects: list[UUID] = Field(
        ...,
        description="List of recommended project UUIDs, ordered by relevance",
        example=[
            "c0343f9a-27ec-4a1e-9ecc-93ed384b836b",
            "d1234567-1234-1234-1234-123456789abc",
            "e9876543-9876-9876-9876-987654321def",
        ],
    )
    total_recommendations: int = Field(
        ..., description="Total number of recommendations returned", example=3
    )

    class Config:
        json_encoders = {UUID: str}
        schema_extra = {
            "example": {
                "user_id": "a75337f8-f424-4f0c-90c2-2d7026b5bce8",
                "recommended_projects": [
                    "c0343f9a-27ec-4a1e-9ecc-93ed384b836b",
                    "d1234567-1234-1234-1234-123456789abc",
                    "e9876543-9876-9876-9876-987654321def",
                ],
                "total_recommendations": 3,
            }
        }


class HealthResponse(BaseModel):
    """
    Response model for health check endpoint.

    Indicates the current status of the API service.
    """

    status: str = Field(
        ..., description="Current health status of the API", example="ok"
    )

    class Config:
        schema_extra = {"example": {"status": "ok"}}


class ErrorResponse(BaseModel):
    """
    Standard error response format for all API endpoints.

    Provides detailed error messages to help clients understand and resolve issues.
    """

    detail: str = Field(
        ...,
        description="Detailed error message explaining what went wrong",
        example="No interest profile found for user.",
    )

    class Config:
        schema_extra = {
            "examples": {
                "user_not_found": {
                    "summary": "User Not Found",
                    "value": {"detail": "No interest profile found for user."},
                },
                "invalid_uuid": {
                    "summary": "Invalid UUID Format",
                    "value": {"detail": "Invalid UUID format for user_id parameter"},
                },
                "models_not_loaded": {
                    "summary": "Models Not Available",
                    "value": {
                        "detail": "Models not available. Run training pipeline first."
                    },
                },
            }
        }


# ============================================================================
# GLOBAL MODEL STORE - IN-MEMORY MODEL ARTIFACTS
# ============================================================================
# This dictionary stores the pre-trained ML models loaded at startup
# for fast inference during recommendation requests.

MODEL_STORE: dict[str, Any] = {
    "similarity_matrix": None,
    "vectorizer": None,
    "projects": [],
}

# ============================================================================
# DATABASE DEPENDENCY INJECTION
# ============================================================================


def get_db():
    """Database session dependency for FastAPI endpoints."""
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()


# ============================================================================
# STARTUP EVENT - MODEL LOADING
# ============================================================================


async def startup_event():
    """
    Load ML models and project data into memory at application startup.

    This ensures fast inference by pre-loading all necessary artifacts:
    - Similarity matrix (project-to-project relationships)
    - Text vectorizer (for feature engineering)
    - Project metadata (for validation and mapping)
    """
    log.info("üöÄ Starting API server...")
    log.info("üì¶ Loading ML models and project data...")

    try:
        # Import services here to avoid circular dependencies
        from src.application.services.project_data_loader import (
            ProjectDataLoadingService,
        )
        from src.infrastructure.analysis.model_persistence_service import (
            ModelPersistenceService,
        )

        # Initialize services
        model_service = ModelPersistenceService()

        # Load all model artifacts from models/ directory
        artifacts = model_service.load_model_artifacts()
        similarity_matrix = artifacts.get("similarity_matrix")
        vectorizer = artifacts.get("tfidf_vectorizer")

        # Load project data for mapping and validation
        with SessionLocal() as db:
            project_service_with_db = ProjectDataLoadingService(db_session=db)
            projects = project_service_with_db.get_training_projects()

        # Store in global cache for fast access
        MODEL_STORE["similarity_matrix"] = similarity_matrix
        MODEL_STORE["vectorizer"] = vectorizer
        MODEL_STORE["projects"] = projects

        # Validate all models loaded successfully
        if (
            MODEL_STORE["similarity_matrix"] is not None
            and MODEL_STORE["vectorizer"] is not None
            and MODEL_STORE["projects"]
        ):
            log.info("üéâ All models loaded successfully!")
        else:
            log.warning("‚ö†Ô∏è Some models failed to load properly")

    except FileNotFoundError as e:
        log.warning("‚ùå Model artifacts not found: %s", str(e))
        MODEL_STORE["similarity_matrix"] = None
        MODEL_STORE["vectorizer"] = None
        MODEL_STORE["projects"] = []
    except Exception as e:
        log.error("‚ùå Error loading models or projects: %s", str(e))
        MODEL_STORE["similarity_matrix"] = None
        MODEL_STORE["vectorizer"] = None
        MODEL_STORE["projects"] = []


# ============================================================================
# FASTAPI APPLICATION SETUP
# ============================================================================

app = FastAPI(
    title="Data Engine Recommendation API",
    description="""## üöÄ Project Recommendation Engine

This API provides personalized project recommendations using ML algorithms.
It analyzes user interactions (contributions, applications, team memberships) to suggest
relevant projects that match their interests and skills.

### üîç How It Works

1. **User Profile Analysis**: Analyzes user's project interactions
2. **Similarity Matching**: Uses ML models to find similar projects
3. **Ranked Recommendations**: Returns top-N most relevant projects

### üìä Features

- **Real-time Recommendations**: Fast inference using pre-loaded models
- **Personalized Results**: Based on actual user behavior and preferences
- **Scalable Architecture**: Designed for high-throughput production use
- **Comprehensive Error Handling**: Clear error messages and status codes

### üõ†Ô∏è Usage

1. **Health Check**: `GET /health` - Verify API status
2. **Get Recommendations**: `GET /recommendations/{user_id}` - Get recommendations

### ü§ñ Algorithm Details

**Model Type**: Content-based filtering with collaborative features
**Text Processing**: TF-IDF vectorization of project descriptions and topics
**Similarity Metric**: Cosine similarity between project feature vectors
**Performance**: ~50-200ms response time for real-time recommendations

### üìà Response Format

All endpoints return JSON with standardized error handling:
- `200`: Successful response with data
- `404`: Resource not found (user has no interactions)
- `422`: Invalid request parameters
- `500`: Internal server error (models not loaded)


""",
    version="1.0.0",
    contact={
        "name": "Data Engine Team",
        "email": "dhicham.pro@gmail.com",
    },
    license_info={
        "name": "MIT",
    },
    tags_metadata=[
        {
            "name": "Health",
            "description": "API health and status endpoints",
        },
        {
            "name": "Recommendations", 
            "description": "Personalized project recommendation endpoints",
        },
    ],
)

# Register startup event
app.add_event_handler("startup", startup_event)

# ============================================================================
# API ENDPOINTS
# ============================================================================



# ----------------------------------------------------------------------------
# HEALTH CHECK ENDPOINT
# ----------------------------------------------------------------------------


@app.get(
    "/health",
    tags=["Health"],
    response_model=HealthResponse,
    summary="üè• Health Check",
    description="Verify that the API is running and models are loaded",
    responses={
        200: {
            "description": "API is healthy and ready to serve recommendations",
            "content": {"application/json": {"example": {"status": "ok"}}},
        }
    },
)
async def health_check():
    """
    **Health Check Endpoint**

    This endpoint provides a quick way to verify that the API service is running
    and operational. It's commonly used by:

    - **Load balancers** to check if the service should receive traffic
    - **Monitoring systems** to track service availability
    - **Deployment pipelines** to verify successful deployments
    - **Development teams** for quick service verification

    **Returns:**
    - `200 OK`: Service is healthy and ready to handle requests
    - `500 Internal Server Error`: Service has critical issues

    **Response Time:** < 10ms (no database or model operations)

    **Usage Examples:**
    ```bash
    # Quick health check
    curl -X GET "http://localhost:8000/health"

    # With verbose output
    curl -v -X GET "http://localhost:8000/health"
    ```
    """
    return HealthResponse(status="ok")


# ----------------------------------------------------------------------------
# RECOMMENDATION ENDPOINT
# ----------------------------------------------------------------------------


@app.get(
    "/recommendations/{user_id}",
    tags=["Recommendations"],
    response_model=RecommendationResponse,
    summary="üéØ Get Personalized Project Recommendations",
    description="Generate personalized project recommendations based on user history",
    responses={
        200: {
            "description": "Successfully generated recommendations",
            "content": {
                "application/json": {
                    "example": {
                        "user_id": "a75337f8-f424-4f0c-90c2-2d7026b5bce8",
                        "recommended_projects": [
                            "c0343f9a-27ec-4a1e-9ecc-93ed384b836b",
                            "d1234567-1234-1234-1234-123456789abc",
                            "e9876543-9876-9876-9876-987654321def",
                        ],
                        "total_recommendations": 3,
                    }
                }
            },
        },
        404: {
            "model": ErrorResponse,
            "description": "User not found or has no interaction history",
            "content": {
                "application/json": {
                    "example": {"detail": "No interest profile found for user."}
                }
            },
        },
        422: {
            "model": ErrorResponse,
            "description": "Invalid request parameters (UUID format or top_n range)",
            "content": {
                "application/json": {
                    "examples": {
                        "invalid_uuid": {
                            "summary": "Invalid UUID",
                            "value": {
                                "detail": "Invalid UUID format for user_id parameter"
                            },
                        },
                        "invalid_top_n": {
                            "summary": "Invalid top_n parameter",
                            "value": {"detail": "Value must be between 1 and 50"},
                        },
                    }
                }
            },
        },
        500: {
            "model": ErrorResponse,
            "description": "Internal server error or models not available",
            "content": {
                "application/json": {
                    "example": {
                        "detail": "Models not available. Run training pipeline first."
                    }
                }
            },
        },
    },
)
async def get_recommendations(
    user_id: UUID = Path(
        ...,
        description="UUID of the user to generate recommendations for",
        example="a75337f8-f424-4a1e-9ecc-93ed384b836b",
    ),
    top_n: int = Query(
        default=10,
        ge=1,
        le=50,
        description="Maximum number of project recommendations to return",
        example=10,
    ),
    db: Session = Depends(get_db),
):
    """
    **üéØ Personalized Project Recommendation Engine**

    This endpoint generates personalized project recommendations using machine learning
    to analyze user behavior and find the most relevant projects.

    ## üîç Algorithm Overview

    **Step 1: Interest Profile Construction**
    - Analyzes user's contribution history, project applications, and team memberships
    - Builds a comprehensive interest profile from user's project interactions
    - Handles users with minimal interaction history gracefully

    **Step 2: Similarity Analysis**
    - Uses pre-trained TF-IDF vectorizer to process project features
    - Calculates cosine similarity between user interests and all available projects
    - Leverages project descriptions, topics, programming languages, and metadata

    **Step 3: Ranking & Filtering**
    - Ranks projects by similarity score (highest first)
    - Excludes projects the user has already interacted with
    - Returns top-N most relevant recommendations

    ## üìã Input Requirements

    - **user_id**: Must be a valid UUID format
    - **top_n**: Integer between 1-50 (default: 10)
    - **User must have interaction history**: At least one contribution or application

    ## üìä Response Format

    Returns a JSON object containing:
    - `user_id`: The input user UUID
    - `recommended_projects`: Array of project UUIDs ordered by relevance
    - `total_recommendations`: Count of returned recommendations

    ## ‚ö†Ô∏è Error Conditions

    - **404 Not Found**: User has no interaction history or doesn't exist
    - **422 Validation Error**: Invalid UUID format or top_n out of range
    - **500 Server Error**: ML models not loaded or database connection issues

    ## üöÄ Performance & Usage Tips

    - **Response Time**: 50-200ms for typical requests
    - **Caching**: Results are computed fresh for each request (real-time)
    - **Rate Limiting**: No built-in limits (implement at gateway level)
    - **Batch Processing**: For multiple users, make parallel requests

    ## üí° Integration Examples

    **Frontend JavaScript:**
    ```javascript
    const response = await fetch(`/recommendations/${userId}?top_n=5`);
    const data = await response.json();
    console.log('Recommended projects:', data.recommended_projects);
    ```

    **Backend Service:**
    ```python
    import httpx
    async with httpx.AsyncClient() as client:
        response = await client.get(f"/recommendations/{user_id}")
        recommendations = response.json()
    ```

    **cURL Command:**
    ```bash
    curl -X GET "http://localhost:8000/recommendations/a75337f8-f424-4f0c-90c2-2d7026b5bce8?top_n=5"
    ```
    """
    try:
        # Check if models are loaded
        if MODEL_STORE["similarity_matrix"] is None:
            log.error("[API] Models not loaded in memory.")
            raise HTTPException(
                status_code=500,
                detail="Models not available. Run training pipeline first.",
            )
        log.info(f"[API] Request for user {user_id} top_n={top_n}")
        log.info(f"[API] Loaded projects: {len(MODEL_STORE['projects'])}")
        log.info(f"[API] Similarity matrix shape: {MODEL_STORE['similarity_matrix'].shape if MODEL_STORE['similarity_matrix'] is not None else 'None'}")
        # Initialize services with correct parameters
        user_service = UserInterestProfileService(db)
        recommendation_service = RecommendationService()
        # Get user's interest profile from PROJECT_training table
        try:
            interest_profile = user_service.get_user_interest_profile_from_training(user_id)
            log.info(f"[API] User {user_id} interest profile: {list(interest_profile)[:5]}{'...' if len(interest_profile) > 5 else ''}")
            if not interest_profile:
                log.warning(f"[API] No interest profile for user {user_id}")
                raise HTTPException(
                    status_code=404,
                    detail=f"No interest profile found for user {user_id}.",
                )
        except Exception as e:
            log.error(f"‚ùå Error fetching user profile for {user_id}: {str(e)}")
            raise HTTPException(
                status_code=404,
                detail=f"No interest profile found for user {user_id}.",
            )
        # Get recommendations using the loaded models
        try:
            log.info(f"[API] Generating recommendations for user {user_id}")
            recommended_project_ids = recommendation_service.get_recommendations(
                interested_project_ids=interest_profile,
                projects=MODEL_STORE["projects"],
                similarity_matrix=MODEL_STORE["similarity_matrix"],
                top_n=top_n,
            )
            log.info(f"[API] Recommendations: {recommended_project_ids}")
            if not recommended_project_ids:
                log.warning(f"[API] No recommendations generated for user {user_id}")
                return RecommendationResponse(
                    user_id=user_id, recommended_projects=[], total_recommendations=0
                )
            count = len(recommended_project_ids)
            log.info(f"[API] Generated {count} recommendations for user {user_id}")
            return RecommendationResponse(
                user_id=user_id,
                recommended_projects=recommended_project_ids,
                total_recommendations=len(recommended_project_ids),
            )
        except Exception as e:
            log.error(
                f"‚ùå Error generating recommendations for user {user_id}: {str(e)}"
            )
            raise HTTPException(
                status_code=500,
                detail="Error generating recommendations. Please try again later.",
            )
    except HTTPException:
        # Re-raise HTTP exceptions as-is
        raise
    except Exception as e:
        # Catch any unexpected errors
        log.error(f"‚ùå Unexpected error in recommendation endpoint: {str(e)}")
        raise HTTPException(
            status_code=500,
            detail="Unexpected error occurred. Please contact support.",
        )


# ============================================================================
# END OF API DEFINITION
# ============================================================================
