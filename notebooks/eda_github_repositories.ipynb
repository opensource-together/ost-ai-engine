{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# Exploratory Data Analysis - GitHub Repositories\n",
        "\n",
        "This notebook analyzes the 500 scraped GitHub repositories to understand:\n",
        "- Data quality and completeness\n",
        "- Distribution of languages, topics, and popularity metrics\n",
        "- Text field characteristics\n",
        "- Potential data preprocessing needs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from collections import Counter\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set up plotting style\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "plt.rcParams['figure.figsize'] = (12, 8)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "# Load data from database\n",
        "import sys\n",
        "sys.path.append('../src')\n",
        "\n",
        "from infrastructure.postgres.database import SessionLocal\n",
        "from domain.models.schema import Project\n",
        "\n",
        "# Connect to database and load all projects\n",
        "db = SessionLocal()\n",
        "try:\n",
        "    projects = db.query(Project).all()\n",
        "    print(f\"Loaded {len(projects)} projects from database\")\n",
        "finally:\n",
        "    db.close()\n",
        "\n",
        "# Convert to DataFrame\n",
        "df = pd.DataFrame([{\n",
        "    'id': p.id,\n",
        "    'title': p.title,\n",
        "    'description': p.description,\n",
        "    'readme': p.readme,\n",
        "    'language': p.language,\n",
        "    'topics': p.topics,\n",
        "    'html_url': p.html_url,\n",
        "    'stargazers_count': p.stargazers_count,\n",
        "    'forks_count': p.forks_count,\n",
        "    'open_issues_count': p.open_issues_count,\n",
        "    'pushed_at': p.pushed_at,\n",
        "    'created_at': p.created_at\n",
        "} for p in projects])\n",
        "\n",
        "print(f\"DataFrame shape: {df.shape}\")\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 1. Data Overview & Quality Assessment\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "# Basic info about the dataset\n",
        "print(\"Dataset Info:\")\n",
        "print(f\"Total repositories: {len(df)}\")\n",
        "print(f\"Features: {df.shape[1]}\")\n",
        "print(\"\\nData types:\")\n",
        "print(df.dtypes)\n",
        "print(\"\\nMemory usage:\")\n",
        "print(df.memory_usage(deep=True).sum() / 1024**2, \"MB\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "# Missing values analysis\n",
        "missing_data = df.isnull().sum()\n",
        "missing_percent = (missing_data / len(df)) * 100\n",
        "missing_df = pd.DataFrame({\n",
        "    'Missing Count': missing_data,\n",
        "    'Missing Percentage': missing_percent\n",
        "})\n",
        "missing_df = missing_df[missing_df['Missing Count'] > 0].sort_values('Missing Count', ascending=False)\n",
        "\n",
        "print(\"Missing Values Summary:\")\n",
        "print(missing_df)\n",
        "\n",
        "# Visualize missing data\n",
        "if not missing_df.empty:\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    missing_df['Missing Percentage'].plot(kind='bar')\n",
        "    plt.title('Missing Data by Column')\n",
        "    plt.ylabel('Missing Percentage (%)')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"✅ No missing values found!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 2. Programming Languages Distribution\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "# Language distribution\n",
        "language_counts = df['language'].value_counts()\n",
        "print(\"Top 15 Programming Languages:\")\n",
        "print(language_counts.head(15))\n",
        "\n",
        "# Plot language distribution\n",
        "plt.figure(figsize=(14, 8))\n",
        "language_counts.head(15).plot(kind='bar')\n",
        "plt.title('Top 15 Programming Languages Distribution')\n",
        "plt.xlabel('Programming Language')\n",
        "plt.ylabel('Number of Repositories')\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Language diversity metrics\n",
        "total_languages = df['language'].nunique()\n",
        "top_5_lang_percent = (language_counts.head(5).sum() / len(df)) * 100\n",
        "print(f\"\\nLanguage Diversity Metrics:\")\n",
        "print(f\"Total unique languages: {total_languages}\")\n",
        "print(f\"Top 5 languages represent: {top_5_lang_percent:.1f}% of repositories\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 3. Data Quality Assessment & Recommendations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "# Topics analysis\n",
        "all_topics = []\n",
        "topics_per_repo = []\n",
        "\n",
        "for topics_str in df['topics'].dropna():\n",
        "    if topics_str and str(topics_str).strip():\n",
        "        topics_list = [topic.strip() for topic in str(topics_str).split(',')]\n",
        "        topics_list = [topic for topic in topics_list if topic]  # Remove empty strings\n",
        "        all_topics.extend(topics_list)\n",
        "        topics_per_repo.append(len(topics_list))\n",
        "    else:\n",
        "        topics_per_repo.append(0)\n",
        "\n",
        "# Add remaining repos with no topics\n",
        "topics_per_repo.extend([0] * (len(df) - len(topics_per_repo)))\n",
        "\n",
        "topics_counter = Counter(all_topics)\n",
        "print(f\"Total unique topics: {len(topics_counter)}\")\n",
        "print(f\"Average topics per repository: {np.mean(topics_per_repo):.2f}\")\n",
        "print(f\"Repositories with no topics: {topics_per_repo.count(0)}\")\n",
        "\n",
        "print(\"\\nTop 10 Most Common Topics:\")\n",
        "for topic, count in topics_counter.most_common(10):\n",
        "    print(f\"{topic}: {count}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "# Final assessment and recommendations\n",
        "print(\"=== DATA QUALITY ASSESSMENT ===\")\n",
        "print()\n",
        "\n",
        "# 1. Missing/Empty data\n",
        "print(\"1. MISSING/EMPTY DATA:\")\n",
        "for field in ['description', 'readme', 'topics', 'language']:\n",
        "    null_count = df[field].isnull().sum()\n",
        "    empty_count = (df[field].astype(str).str.strip() == '').sum()\n",
        "    total_missing = null_count + empty_count\n",
        "    percentage = (total_missing / len(df)) * 100\n",
        "    print(f\"   {field}: {total_missing} missing ({percentage:.1f}%)\")\n",
        "\n",
        "print()\n",
        "\n",
        "# 2. Data distribution issues\n",
        "print(\"2. DATA DISTRIBUTION:\")\n",
        "print(f\"   Language concentration: Top 5 languages = {top_5_lang_percent:.1f}% of data\")\n",
        "print(f\"   Repositories with no topics: {topics_per_repo.count(0)} ({(topics_per_repo.count(0)/len(df)*100):.1f}%)\")\n",
        "print(f\"   Star distribution: Median = {df['stargazers_count'].median()}, Mean = {df['stargazers_count'].mean():.0f}\")\n",
        "\n",
        "print()\n",
        "\n",
        "# 3. Recommendations\n",
        "print(\"3. PREPROCESSING RECOMMENDATIONS:\")\n",
        "print(\"   ✓ Handle missing descriptions/readmes (fill with title or remove)\")\n",
        "print(\"   ✓ Standardize topics format (split, clean, lowercase)\")\n",
        "print(\"   ✓ Consider log-scaling for star counts (highly skewed)\")\n",
        "print(\"   ✓ Text cleaning: remove special chars, normalize whitespace\")\n",
        "print(\"   ✓ Language balancing: consider sampling to reduce dominance\")\n",
        "\n",
        "if top_5_lang_percent > 80:\n",
        "    print(\"   ⚠️  HIGH LANGUAGE CONCENTRATION - Consider data balancing\")\n",
        "    \n",
        "if topics_per_repo.count(0) > len(df) * 0.3:\n",
        "    print(\"   ⚠️  MANY REPOS WITHOUT TOPICS - Consider topic extraction from descriptions\")\n",
        "\n",
        "print()\n",
        "print(\"=== DATASET READINESS FOR ML ===\")\n",
        "print(\"✅ Sufficient size for initial training (500 repos)\")\n",
        "print(\"✅ Good text features available for TF-IDF\")\n",
        "print(\"✅ Numerical features for scaling\")\n",
        "print(\"📈 Recommendation: Scale to 1500-2000 repos for better quality\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "data-engine-py13",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
